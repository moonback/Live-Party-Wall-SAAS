/**
 * Service combin√© pour l'IA Gemini
 * Combine mod√©ration et g√©n√©ration de l√©gende en 1 seul appel API
 * R√©duit les co√ªts de 50% (1 appel au lieu de 2)
 * Cache les r√©sultats pour √©viter les appels API pour images identiques
 */

import { GoogleGenAI } from "@google/genai";
import { buildPersonalizedCaptionPrompt } from '../constants';
import { ImageAnalysis } from './aiModerationService';
import { logger } from '../utils/logger';
import { getImageHash } from '../utils/imageHash';
import { 
  detectGeminiErrorType, 
  logGeminiError 
} from '../utils/geminiErrorHandler';

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Cache en m√©moire pour les analyses (√©vite les appels API pour images identiques)
// Structure : Map<hash, { result: CombinedAnalysisResult, timestamp: number }>
const analysisCache = new Map<string, { result: CombinedAnalysisResult; timestamp: number }>();

// Dur√©e de vie du cache : 1 heure (3600000 ms)
const CACHE_TTL = 60 * 60 * 1000;

// Taille max du cache : 100 entr√©es (√©vite la consommation m√©moire excessive)
const MAX_CACHE_SIZE = 100;

/**
 * Nettoie le cache des entr√©es expir√©es ou trop anciennes
 */
function cleanCache(): void {
  const now = Date.now();
  const entries = Array.from(analysisCache.entries());
  
  // Supprimer les entr√©es expir√©es
  for (const [hash, value] of entries) {
    if (now - value.timestamp > CACHE_TTL) {
      analysisCache.delete(hash);
    }
  }
  
  // Si le cache est encore trop grand, supprimer les plus anciennes
  if (analysisCache.size > MAX_CACHE_SIZE) {
    const sorted = Array.from(analysisCache.entries())
      .sort((a, b) => a[1].timestamp - b[1].timestamp);
    
    const toDelete = sorted.slice(0, analysisCache.size - MAX_CACHE_SIZE);
    for (const [hash] of toDelete) {
      analysisCache.delete(hash);
    }
  }
}

export interface CombinedAnalysisResult {
  analysis: ImageAnalysis;
  caption: string;
  tags: string[]; // Tags sugg√©r√©s par l'IA (ex: ['sourire', 'groupe', 'danse', 'f√™te'])
}

/**
 * Analyse une image et g√©n√®re une l√©gende en 1 seul appel API Gemini
 * Combine mod√©ration + l√©gende pour r√©duire les co√ªts
 * 
 * @param base64Image - Image en base64
 * @param eventContext - Contexte optionnel de l'√©v√©nement pour personnaliser les l√©gendes
 * @returns Promise<CombinedAnalysisResult> - Analyse compl√®te + l√©gende
 */
export const analyzeAndCaptionImage = async (
  base64Image: string,
  eventContext?: string | null
): Promise<CombinedAnalysisResult> => {
  try {
    // Validation de l'input
    if (!base64Image || base64Image.trim().length === 0) {
      logger.warn('Empty base64 image provided to analyzeAndCaptionImage', null, {
        component: 'aiService',
        action: 'analyzeAndCaptionImage'
      });
      // Retourner un fallback imm√©diatement
      return {
        analysis: {
          hasFaces: false,
          faceCount: 0,
          isAppropriate: true,
          suggestedFilter: 'none',
          quality: 'fair',
          estimatedQuality: 'fair',
          suggestedImprovements: [],
        },
        caption: "Party time! üéâ",
        tags: [],
      };
    }

    // Nettoyer le cache p√©riodiquement
    cleanCache();
    
    // G√©n√©rer un hash de l'image pour le cache
    // Le hash inclut aussi le contexte de l'√©v√©nement (car la l√©gende d√©pend du contexte)
    const imageHash = await getImageHash(base64Image);
    const cacheKey = `${imageHash}_${eventContext || 'default'}`;
    
    // V√©rifier le cache
    const cached = analysisCache.get(cacheKey);
    if (cached && (Date.now() - cached.timestamp) < CACHE_TTL) {
      logger.debug('Cache hit for image analysis', { hash: imageHash.substring(0, 8) });
      return cached.result;
    }
    
    logger.debug('Cache miss, calling Gemini API', { hash: imageHash.substring(0, 8) });
    
    // Strip the data:image/xyz;base64, prefix if present
    const cleanBase64 = base64Image.split(',')[1] || base64Image;

    // Construire le prompt personnalis√© pour la l√©gende
    const captionPrompt = buildPersonalizedCaptionPrompt(eventContext);

    // Prompt combin√© : mod√©ration + l√©gende + tags + am√©liorations
    const combinedPrompt = `
Analyse cette photo de f√™te et r√©ponds UNIQUEMENT avec un JSON valide (sans markdown, sans code blocks) avec cette structure exacte :
{
  "hasFaces": boolean,
  "faceCount": number,
  "isAppropriate": boolean,
  "moderationReason": string | null,
  "suggestedFilter": "none" | "vintage" | "blackwhite" | "warm" | "cool",
  "quality": "good" | "fair" | "poor",
  "estimatedQuality": "excellent" | "good" | "fair" | "poor",
  "suggestedImprovements": string[],
  "caption": string,
  "tags": string[]
}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
R√àGLES DE MOD√âRATION (ANALYSE TECHNIQUE)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. hasFaces: true si la photo contient des visages humains clairement visibles (m√™me partiels ou de profil)
2. faceCount: nombre exact de visages d√©tect√©s (0 si aucun, compte m√™me les visages partiels)
3. isAppropriate: false UNIQUEMENT si la photo contient du contenu inappropri√© :
   - Nudit√© explicite ou suggestive
   - Violence, agression, contenu choquant
   - Contenu offensant, discriminatoire, haineux
   - Contenu ill√©gal
   - Par d√©faut, isAppropriate = true (sois tol√©rant pour les photos de f√™te normales)
4. moderationReason: raison d√©taill√©e si isAppropriate est false, sinon null
5. suggestedFilter: sugg√®re un filtre esth√©tique bas√© sur l'ambiance :
   - "vintage" : photos r√©tro, ambiance ann√©es 70-80, tons s√©pia
   - "warm" : ambiance chaleureuse, tons orang√©s/jaunes, intime
   - "cool" : ambiance moderne/froide, tons bleus/violets, dynamique
   - "blackwhite" : photos artistiques, contrastes forts, √©l√©gant
   - "none" : aucun filtre n√©cessaire, photo d√©j√† optimale
6. quality: √©value la qualit√© technique :
   - "good" : nette, bien expos√©e, bonne composition
   - "fair" : acceptable, l√©g√®rement floue ou sous/expos√©e
   - "poor" : tr√®s floue, tr√®s mal expos√©e, composition probl√©matique
7. estimatedQuality: √©valuation plus pr√©cise :
   - "excellent" : parfaite, professionnelle
   - "good" : tr√®s bonne qualit√©
   - "fair" : correcte mais perfectible
   - "poor" : √† am√©liorer significativement
8. suggestedImprovements: tableau de suggestions concr√®tes (max 5) :
   - Exemples : ["am√©liorer luminosit√©", "recadrer", "r√©duire bruit", "ajuster contraste"]
   - Tableau vide [] si aucune am√©lioration n√©cessaire

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
R√àGLES DE L√âGENDE (CR√âATIVIT√â ET PERSONNALISATION)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

${captionPrompt}

‚ö†Ô∏è RAPPEL CRITIQUE POUR LA L√âGENDE :
- Analyse d'abord la photo en d√©tail (personnes, objets, actions, expressions)
- La l√©gende DOIT √™tre sp√©cifique √† cette photo, pas g√©n√©rique
- Maximum 12 mots, uniquement en fran√ßais
- Utilise 1-3 √©mojis pertinents maximum
- Base-toi sur ce que tu vois r√©ellement, jamais d'invention
- Le champ "caption" doit contenir UNIQUEMENT la l√©gende, rien d'autre
- Si un contexte d'√©v√©nement est fourni, REPRENDS SON TON HUMORISTIQUE ET FESTIF dans ta l√©gende
- Le contexte a √©t√© cr√©√© pour √™tre humoristique - adapte cette √©nergie √† chaque photo unique

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
R√àGLES DE TAGS (M√âTADONN√âES)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

- tags: tableau de 3 √† 8 tags pertinents en fran√ßais d√©crivant la photo
- Tags possibles par cat√©gorie :
  * Actions : danse, rire, c√©l√©brer, sourire, trinquer, embrasser, poser, jouer
  * Personnes : groupe, couple, famille, amis, individu, selfie
  * Ambiance : f√™te, joie, √©motion, moment, complicit√©, tendresse
  * Objets : g√¢teau, d√©coration, musique, verre, bouquet, cadeau
  * Lieux : int√©rieur, ext√©rieur, sc√®ne, salle, jardin, plage
  * √âv√©nements : mariage, anniversaire, c√©l√©bration, toast, danse
- Utilise des mots simples et descriptifs, en minuscules
- Choisis les tags les plus pertinents pour cette photo sp√©cifique
- Exemples :
  * Photo de groupe qui danse : ["groupe", "danse", "f√™te", "joie", "mouvement"]
  * Photo de couple qui trinque : ["couple", "toast", "c√©l√©bration", "complicit√©", "verre"]
  * Photo de g√¢teau : ["g√¢teau", "anniversaire", "c√©l√©bration", "bougies", "f√™te"]

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
INSTRUCTIONS FINALES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. Analyse d'abord la photo en d√©tail (mod√©ration + contenu)
2. G√©n√®re ensuite la l√©gende selon les r√®gles d√©taill√©es ci-dessus
3. Cr√©e les tags pertinents bas√©s sur l'analyse
4. R√©ponds UNIQUEMENT avec le JSON valide, sans markdown, sans code blocks
5. V√©rifie que tous les champs sont pr√©sents et correctement typ√©s
6. Le JSON doit √™tre valide et parsable directement

FORMAT DE R√âPONSE ATTENDU (exemple) :
{
  "hasFaces": true,
  "faceCount": 3,
  "isAppropriate": true,
  "moderationReason": null,
  "suggestedFilter": "warm",
  "quality": "good",
  "estimatedQuality": "good",
  "suggestedImprovements": [],
  "caption": "Sourires radieux qui illuminent la soir√©e ! üòä‚ú®",
  "tags": ["groupe", "sourire", "f√™te", "joie", "complicit√©"]
}
`;

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash', // Mod√®le moins cher que gemini-3-flash-preview
      contents: {
        parts: [
          {
            inlineData: {
              data: cleanBase64,
              mimeType: 'image/jpeg',
            },
          },
          {
            text: combinedPrompt,
          },
        ],
      },
    });

    const responseText = response.text.trim();
    
    if (!responseText || responseText.length === 0) {
      logger.warn('Empty response from Gemini in analyzeAndCaptionImage', null, {
        component: 'aiService',
        action: 'analyzeAndCaptionImage'
      });
      // Retourner un fallback
      return {
        analysis: {
          hasFaces: false,
          faceCount: 0,
          isAppropriate: true,
          suggestedFilter: 'none',
          quality: 'fair',
          estimatedQuality: 'fair',
          suggestedImprovements: [],
        },
        caption: "Party time! üéâ",
        tags: [],
      };
    }
    
    // Nettoyer la r√©ponse (enlever markdown si pr√©sent)
    let jsonText = responseText;
    if (jsonText.startsWith('```json')) {
      jsonText = jsonText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
    } else if (jsonText.startsWith('```')) {
      jsonText = jsonText.replace(/```\n?/g, '');
    }

    let parsed: {
      hasFaces?: boolean;
      faceCount?: number;
      isAppropriate?: boolean;
      moderationReason?: string | null;
      suggestedFilter?: 'none' | 'vintage' | 'blackwhite' | 'warm' | 'cool';
      quality?: 'good' | 'fair' | 'poor';
      estimatedQuality?: 'excellent' | 'good' | 'fair' | 'poor';
      suggestedImprovements?: string[];
      caption?: string;
      tags?: string[];
    };

    try {
      parsed = JSON.parse(jsonText);
    } catch (parseError) {
      logger.error('Failed to parse Gemini response as JSON', parseError, {
        component: 'aiService',
        action: 'analyzeAndCaptionImage',
        responseText: responseText.substring(0, 200) // Log les 200 premiers caract√®res
      });
      // Retourner un fallback en cas d'erreur de parsing
      return {
        analysis: {
          hasFaces: false,
          faceCount: 0,
          isAppropriate: true,
          suggestedFilter: 'none',
          quality: 'fair',
          estimatedQuality: 'fair',
          suggestedImprovements: [],
        },
        caption: "Party time! üéâ",
        tags: [],
      };
    }

    // Validation et valeurs par d√©faut pour l'analyse
    const analysis: ImageAnalysis = {
      hasFaces: parsed.hasFaces ?? false,
      faceCount: parsed.faceCount ?? 0,
      isAppropriate: parsed.isAppropriate ?? true,
      moderationReason: parsed.moderationReason || undefined,
      suggestedFilter: parsed.suggestedFilter || 'none',
      quality: parsed.quality || 'good',
      estimatedQuality: parsed.estimatedQuality || parsed.quality || 'good',
      suggestedImprovements: Array.isArray(parsed.suggestedImprovements) ? parsed.suggestedImprovements : [],
    };

    // Validation et fallback pour la l√©gende
    const caption = parsed.caption?.trim() || "Party time! üéâ";

    // Validation et fallback pour les tags
    const tags = Array.isArray(parsed.tags) && parsed.tags.length > 0 
      ? parsed.tags.filter(tag => typeof tag === 'string' && tag.trim().length > 0).slice(0, 8) // Max 8 tags
      : [];

    const result: CombinedAnalysisResult = {
      analysis,
      caption,
      tags,
    };
    
    // Mettre en cache le r√©sultat
    analysisCache.set(cacheKey, {
      result,
      timestamp: Date.now()
    });
    
    return result;

  } catch (error) {
    // D√©tecter le type d'erreur
    const errorType = detectGeminiErrorType(error);
    
    // Logger l'erreur avec le contexte
    logGeminiError(error, errorType, {
      component: 'aiService',
      action: 'analyzeAndCaptionImage',
      eventContext: eventContext || 'none'
    });
    
    // Fallback en cas d'erreur - toujours retourner des valeurs s√ªres
    // pour √©viter que l'application plante
    return {
      analysis: {
        hasFaces: false,
        faceCount: 0,
        isAppropriate: true, // Par d√©faut, on accepte (mais on log l'erreur)
        suggestedFilter: 'none',
        quality: 'fair',
        estimatedQuality: 'fair',
        suggestedImprovements: [],
      },
      caption: "Party time! üéâ", // L√©gende par d√©faut coh√©rente avec geminiService
      tags: [],
    };
  }
};

/**
 * V√©rifie si une image est appropri√©e pour le mur
 * Utilise le service combin√© mais ne retourne que la partie mod√©ration
 * 
 * @param base64Image - Image en base64
 * @returns Promise avec approved, reason et analysis
 */
export const isImageAppropriate = async (base64Image: string): Promise<{ 
  approved: boolean; 
  reason?: string;
  analysis?: ImageAnalysis;
}> => {
  const result = await analyzeAndCaptionImage(base64Image);
  
  if (!result.analysis.isAppropriate) {
    return {
      approved: false,
      reason: result.analysis.moderationReason || "Contenu inappropri√© d√©tect√©",
      analysis: result.analysis,
    };
  }

  return {
    approved: true,
    analysis: result.analysis,
  };
};

