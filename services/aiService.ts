/**
 * Service combin√© pour l'IA Gemini
 * Combine mod√©ration et g√©n√©ration de l√©gende en 1 seul appel API
 * R√©duit les co√ªts de 50% (1 appel au lieu de 2)
 * Cache les r√©sultats pour √©viter les appels API pour images identiques
 */

import { GoogleGenAI } from "@google/genai";
import { buildPersonalizedCaptionPrompt } from '../constants';
import { ImageAnalysis } from './aiModerationService';
import { logger } from '../utils/logger';
import { getImageHash } from '../utils/imageHash';
import { 
  detectGeminiErrorType, 
  logGeminiError 
} from '../utils/geminiErrorHandler';

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Cache en m√©moire pour les analyses (√©vite les appels API pour images identiques)
// Structure : Map<hash, { result: CombinedAnalysisResult, timestamp: number }>
const analysisCache = new Map<string, { result: CombinedAnalysisResult; timestamp: number }>();

// Dur√©e de vie du cache : 1 heure (3600000 ms)
const CACHE_TTL = 60 * 60 * 1000;

// Taille max du cache : 100 entr√©es (√©vite la consommation m√©moire excessive)
const MAX_CACHE_SIZE = 100;

/**
 * Nettoie le cache des entr√©es expir√©es ou trop anciennes
 */
function cleanCache(): void {
  const now = Date.now();
  const entries = Array.from(analysisCache.entries());
  
  // Supprimer les entr√©es expir√©es
  for (const [hash, value] of entries) {
    if (now - value.timestamp > CACHE_TTL) {
      analysisCache.delete(hash);
    }
  }
  
  // Si le cache est encore trop grand, supprimer les plus anciennes
  if (analysisCache.size > MAX_CACHE_SIZE) {
    const sorted = Array.from(analysisCache.entries())
      .sort((a, b) => a[1].timestamp - b[1].timestamp);
    
    const toDelete = sorted.slice(0, analysisCache.size - MAX_CACHE_SIZE);
    for (const [hash] of toDelete) {
      analysisCache.delete(hash);
    }
  }
}

export interface CombinedAnalysisResult {
  analysis: ImageAnalysis;
  caption: string;
}

/**
 * Analyse une image et g√©n√®re une l√©gende en 1 seul appel API Gemini
 * Combine mod√©ration + l√©gende pour r√©duire les co√ªts
 * 
 * @param base64Image - Image en base64
 * @param eventContext - Contexte optionnel de l'√©v√©nement pour personnaliser les l√©gendes
 * @returns Promise<CombinedAnalysisResult> - Analyse compl√®te + l√©gende
 */
export const analyzeAndCaptionImage = async (
  base64Image: string,
  eventContext?: string | null
): Promise<CombinedAnalysisResult> => {
  try {
    // Validation de l'input
    if (!base64Image || base64Image.trim().length === 0) {
      logger.warn('Empty base64 image provided to analyzeAndCaptionImage', null, {
        component: 'aiService',
        action: 'analyzeAndCaptionImage'
      });
      // Retourner un fallback imm√©diatement
      return {
        analysis: {
          hasFaces: false,
          faceCount: 0,
          isAppropriate: true,
          suggestedFilter: 'none',
          quality: 'fair',
        },
        caption: "Party time! üéâ",
      };
    }

    // Nettoyer le cache p√©riodiquement
    cleanCache();
    
    // G√©n√©rer un hash de l'image pour le cache
    // Le hash inclut aussi le contexte de l'√©v√©nement (car la l√©gende d√©pend du contexte)
    const imageHash = await getImageHash(base64Image);
    const cacheKey = `${imageHash}_${eventContext || 'default'}`;
    
    // V√©rifier le cache
    const cached = analysisCache.get(cacheKey);
    if (cached && (Date.now() - cached.timestamp) < CACHE_TTL) {
      logger.debug('Cache hit for image analysis', { hash: imageHash.substring(0, 8) });
      return cached.result;
    }
    
    logger.debug('Cache miss, calling Gemini API', { hash: imageHash.substring(0, 8) });
    
    // Strip the data:image/xyz;base64, prefix if present
    const cleanBase64 = base64Image.split(',')[1] || base64Image;

    // Construire le prompt personnalis√© pour la l√©gende
    const captionPrompt = buildPersonalizedCaptionPrompt(eventContext);

    // Prompt combin√© : mod√©ration + l√©gende
    const combinedPrompt = `
Analyse cette photo de f√™te et r√©ponds UNIQUEMENT avec un JSON valide (sans markdown, sans code blocks) avec cette structure exacte :
{
  "hasFaces": boolean,
  "faceCount": number,
  "isAppropriate": boolean,
  "moderationReason": string | null,
  "suggestedFilter": "none" | "vintage" | "blackwhite" | "warm" | "cool",
  "quality": "good" | "fair" | "poor",
  "caption": string
}

R√àGLES DE MOD√âRATION :
1. hasFaces: true si la photo contient des visages humains clairement visibles
2. faceCount: nombre de visages d√©tect√©s (0 si aucun)
3. isAppropriate: false si la photo contient du contenu inappropri√© (nudit√©, violence, contenu offensant, contenu ill√©gal)
4. moderationReason: raison si isAppropriate est false, sinon null
5. suggestedFilter: sugg√®re un filtre esth√©tique bas√© sur l'ambiance (vintage pour photos r√©tro, warm pour ambiance chaleureuse, cool pour ambiance moderne/froide, blackwhite pour photos artistiques, none si aucun filtre n√©cessaire)
6. quality: √©value la qualit√© technique (good: nette et bien expos√©e, fair: acceptable, poor: floue ou mal expos√©e)

R√àGLES DE L√âGENDE :
${captionPrompt}

IMPORTANT : 
- R√©ponds UNIQUEMENT avec le JSON, rien d'autre
- Le champ "caption" doit contenir la l√©gende g√©n√©r√©e selon les r√®gles ci-dessus
- Maximum 12 mots pour la l√©gende, uniquement en fran√ßais
`;

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash', // Mod√®le moins cher que gemini-3-flash-preview
      contents: {
        parts: [
          {
            inlineData: {
              data: cleanBase64,
              mimeType: 'image/jpeg',
            },
          },
          {
            text: combinedPrompt,
          },
        ],
      },
    });

    const responseText = response.text.trim();
    
    if (!responseText || responseText.length === 0) {
      logger.warn('Empty response from Gemini in analyzeAndCaptionImage', null, {
        component: 'aiService',
        action: 'analyzeAndCaptionImage'
      });
      // Retourner un fallback
      return {
        analysis: {
          hasFaces: false,
          faceCount: 0,
          isAppropriate: true,
          suggestedFilter: 'none',
          quality: 'fair',
        },
        caption: "Party time! üéâ",
      };
    }
    
    // Nettoyer la r√©ponse (enlever markdown si pr√©sent)
    let jsonText = responseText;
    if (jsonText.startsWith('```json')) {
      jsonText = jsonText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
    } else if (jsonText.startsWith('```')) {
      jsonText = jsonText.replace(/```\n?/g, '');
    }

    let parsed: {
      hasFaces?: boolean;
      faceCount?: number;
      isAppropriate?: boolean;
      moderationReason?: string | null;
      suggestedFilter?: 'none' | 'vintage' | 'blackwhite' | 'warm' | 'cool';
      quality?: 'good' | 'fair' | 'poor';
      caption?: string;
    };

    try {
      parsed = JSON.parse(jsonText);
    } catch (parseError) {
      logger.error('Failed to parse Gemini response as JSON', parseError, {
        component: 'aiService',
        action: 'analyzeAndCaptionImage',
        responseText: responseText.substring(0, 200) // Log les 200 premiers caract√®res
      });
      // Retourner un fallback en cas d'erreur de parsing
      return {
        analysis: {
          hasFaces: false,
          faceCount: 0,
          isAppropriate: true,
          suggestedFilter: 'none',
          quality: 'fair',
        },
        caption: "Party time! üéâ",
      };
    }

    // Validation et valeurs par d√©faut pour l'analyse
    const analysis: ImageAnalysis = {
      hasFaces: parsed.hasFaces ?? false,
      faceCount: parsed.faceCount ?? 0,
      isAppropriate: parsed.isAppropriate ?? true,
      moderationReason: parsed.moderationReason || undefined,
      suggestedFilter: parsed.suggestedFilter || 'none',
      quality: parsed.quality || 'good',
    };

    // Validation et fallback pour la l√©gende
    const caption = parsed.caption?.trim() || "Party time! üéâ";

    const result: CombinedAnalysisResult = {
      analysis,
      caption,
    };
    
    // Mettre en cache le r√©sultat
    analysisCache.set(cacheKey, {
      result,
      timestamp: Date.now()
    });
    
    return result;

  } catch (error) {
    // D√©tecter le type d'erreur
    const errorType = detectGeminiErrorType(error);
    
    // Logger l'erreur avec le contexte
    logGeminiError(error, errorType, {
      component: 'aiService',
      action: 'analyzeAndCaptionImage',
      eventContext: eventContext || 'none'
    });
    
    // Fallback en cas d'erreur - toujours retourner des valeurs s√ªres
    // pour √©viter que l'application plante
    return {
      analysis: {
        hasFaces: false,
        faceCount: 0,
        isAppropriate: true, // Par d√©faut, on accepte (mais on log l'erreur)
        suggestedFilter: 'none',
        quality: 'fair',
      },
      caption: "Party time! üéâ", // L√©gende par d√©faut coh√©rente avec geminiService
    };
  }
};

/**
 * V√©rifie si une image est appropri√©e pour le mur
 * Utilise le service combin√© mais ne retourne que la partie mod√©ration
 * 
 * @param base64Image - Image en base64
 * @returns Promise avec approved, reason et analysis
 */
export const isImageAppropriate = async (base64Image: string): Promise<{ 
  approved: boolean; 
  reason?: string;
  analysis?: ImageAnalysis;
}> => {
  const result = await analyzeAndCaptionImage(base64Image);
  
  if (!result.analysis.isAppropriate) {
    return {
      approved: false,
      reason: result.analysis.moderationReason || "Contenu inappropri√© d√©tect√©",
      analysis: result.analysis,
    };
  }

  return {
    approved: true,
    analysis: result.analysis,
  };
};

